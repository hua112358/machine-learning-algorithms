{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#导入数据\n",
    "from sklearn import datasets\n",
    "news_dataset_train = datasets.fetch_20newsgroups(subset = 'train')\n",
    "news_dataset_test = datasets.fetch_20newsgroups(subset = 'test')\n",
    "X_train = news_dataset_train.data\n",
    "y_train = news_dataset_train.target\n",
    "X_test = news_dataset_test.data\n",
    "y_test = news_dataset_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#预处理：CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vectorizer_transformer = CountVectorizer()\n",
    "count_vectorizer_transformer.fit(X_train)\n",
    "X_train_transformed_count = count_vectorizer_transformer.transform(X_train)\n",
    "X_test_transformed_count = count_vectorizer_transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the average score of 81.2%\n"
     ]
    }
   ],
   "source": [
    "#构建、评估分类器\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "multinomialnb_clf = MultinomialNB()\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(multinomialnb_clf,X_train_transformed_count,y_train,scoring = 'accuracy')\n",
    "import numpy as np\n",
    "print('the average score of {0:.1f}%'.format(np.mean(scores)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#预处理：TfidfTransformer(将单词出现次数转化为单词出现频率)\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidf_transformer.fit(X_train_transformed_count)\n",
    "X_train_transformed_tfidf = tfidf_transformer.transform(X_train_transformed_count)\n",
    "X_test_transformed_tfidf = tfidf_transformer.transform(X_test_transformed_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the average score of 82.7%\n"
     ]
    }
   ],
   "source": [
    "#构建、评估分类器\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "multinomialnb_clf = MultinomialNB()\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(multinomialnb_clf,X_train_transformed_tfidf,y_train,scoring = 'accuracy')\n",
    "import numpy as np\n",
    "print('the average score of {0:.1f}%'.format(np.mean(scores)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#预处理：TfidfVectorizer(直接将原数据转化为单词出现频率)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidfvectorizer_transformer = TfidfVectorizer()\n",
    "tfidfvectorizer_transformer.fit(X_train)\n",
    "X_train_transformed_tfidfvect = tfidfvectorizer_transformer.transform(X_train)\n",
    "X_test_transformed_tfidfvect = tfidfvectorizer_transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the average score of 82.7%\n"
     ]
    }
   ],
   "source": [
    "#构建、评估分类器\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "multinomialnb_clf = MultinomialNB()\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(multinomialnb_clf,X_train_transformed_tfidfvect,y_train,scoring = 'accuracy')\n",
    "import numpy as np\n",
    "print('the average score of {0:.1f}%'.format(np.mean(scores)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#预处理：\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "hashingvectorizer_transformer = HashingVectorizer(non_negative = True)\n",
    "hashingvectorizer_transformer.fit(X_train)\n",
    "X_train_transformed_hash = hashingvectorizer_transformer.transform(X_train)\n",
    "X_test_transformed_hash = hashingvectorizer_transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the average score of 73.4%\n"
     ]
    }
   ],
   "source": [
    "#构建、评估分类器\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "multinomialnb_clf = MultinomialNB()\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(multinomialnb_clf,X_train_transformed_hash,y_train,scoring = 'accuracy')\n",
    "import numpy as np\n",
    "print('the average score of {0:.1f}%'.format(np.mean(scores)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.772835900159\n"
     ]
    }
   ],
   "source": [
    "#测试分类器\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "multinomialnb_clf = MultinomialNB()\n",
    "multinomialnb_clf.fit(X_train_transformed_count,y_train)\n",
    "y_predicted = multinomialnb_clf.predict(X_test_transformed_count)\n",
    "import numpy as np\n",
    "print(np.mean(y_test == y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77389803505\n"
     ]
    }
   ],
   "source": [
    "#测试分类器\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "multinomialnb_clf = MultinomialNB()\n",
    "multinomialnb_clf.fit(X_train_transformed_tfidf,y_train)\n",
    "y_predicted = multinomialnb_clf.predict(X_test_transformed_tfidf)\n",
    "import numpy as np\n",
    "print(np.mean(y_test == y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77389803505\n"
     ]
    }
   ],
   "source": [
    "#测试分类器\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "multinomialnb_clf = MultinomialNB()\n",
    "multinomialnb_clf.fit(X_train_transformed_tfidfvect,y_train)\n",
    "y_predicted = multinomialnb_clf.predict(X_test_transformed_tfidfvect)\n",
    "import numpy as np\n",
    "print(np.mean(y_test == y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.701540095592\n"
     ]
    }
   ],
   "source": [
    "#测试分类器\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "multinomialnb_clf = MultinomialNB()\n",
    "multinomialnb_clf.fit(X_train_transformed_hash,y_train)\n",
    "y_predicted = multinomialnb_clf.predict(X_test_transformed_hash)\n",
    "import numpy as np\n",
    "print(np.mean(y_test == y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#构建pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer,TfidfVectorizer,HashingVectorizer\n",
    "countvectorizer_multinomialnb_pipeline = Pipeline([('count_vectorizer_transformer',CountVectorizer()),\n",
    "                                                  ('multinomialnb_clf',MultinomialNB())])\n",
    "tfidf_multinomialnb_pipeline = Pipeline([('tfidf_transformer',TfidfTransformer()),\n",
    "                                         ('multinomialnb_clf',MultinomialNB())])\n",
    "tfidfvectorizer_multinomialnb_pipeline = Pipeline([('tfidfvectorizer_transformer',TfidfVectorizer()),\n",
    "                                                   ('multinomialnb_clf',MultinomialNB())])\n",
    "hashingvectorizer_multinomialnb_pipeline = Pipeline([('hashingvectorizer_transformer',HashingVectorizer(non_negative = True)),\n",
    "                                                  ('multinomialnb_clf',MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the average score is 82.1%\n"
     ]
    }
   ],
   "source": [
    "#评估countvectorizer_multinomialnb_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores_countvectorizer_multinomialnb_pipeline = cross_val_score(countvectorizer_multinomialnb_pipeline,\n",
    "                                                               X_train,y_train,scoring = 'accuracy')\n",
    "print('the average score is {0:.1f}%'.format(np.mean(scores_countvectorizer_multinomialnb_pipeline)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the average score is 82.8%\n"
     ]
    }
   ],
   "source": [
    "#评估tfidf_multinomialnb_pipeline \n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores_tfidf_multinomialnb_pipeline = cross_val_score(tfidf_multinomialnb_pipeline,X_train_transformed_count,y_train,scoring = 'accuracy')\n",
    "print('the average score is {0:.1f}%'.format(np.mean(scores_tfidf_multinomialnb_pipeline)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the average score is 83.0%\n"
     ]
    }
   ],
   "source": [
    "#评估tfidfvectorizer_multinomialnb_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores_tfidfvectorizer_multinomialnb_pipeline = cross_val_score(tfidfvectorizer_multinomialnb_pipeline,\n",
    "                                                               X_train,y_train,scoring = 'accuracy')\n",
    "print('the average score is {0:.1f}%'.format(np.mean(scores_tfidfvectorizer_multinomialnb_pipeline)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the average score is 73.4%\n"
     ]
    }
   ],
   "source": [
    "#评估hashingvectorizer_multinomialnb_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores_hashingvectorizer_multinomialnb_pipeline = cross_val_score(hashingvectorizer_multinomialnb_pipeline,\n",
    "                                                               X_train,y_train,scoring = 'accuracy')\n",
    "print('the average score is {0:.1f}%'.format(np.mean(scores_hashingvectorizer_multinomialnb_pipeline)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.772835900159\n",
      "0.77389803505\n",
      "0.77389803505\n",
      "0.701540095592\n"
     ]
    }
   ],
   "source": [
    "#测试pipeline\n",
    "countvectorizer_multinomialnb_pipeline.fit(X_train,y_train)\n",
    "tfidf_multinomialnb_pipeline.fit(X_train_transformed_count,y_train)\n",
    "tfidfvectorizer_multinomialnb_pipeline.fit(X_train,y_train)\n",
    "hashingvectorizer_multinomialnb_pipeline.fit(X_train,y_train)\n",
    "y_predicted_countvectorizer = countvectorizer_multinomialnb_pipeline.predict(X_test)\n",
    "y_predicted_tfidf = tfidf_multinomialnb_pipeline.predict(X_test_transformed_count)\n",
    "y_predicted_tfidfvect = tfidfvectorizer_multinomialnb_pipeline.predict(X_test)\n",
    "y_predicted_hashingvectorizer = hashingvectorizer_multinomialnb_pipeline.predict(X_test)\n",
    "print(np.mean(y_predicted_countvectorizer == y_test))\n",
    "print(np.mean(y_predicted_tfidf == y_test))\n",
    "print(np.mean(y_predicted_tfidfvect == y_test))\n",
    "print(np.mean(y_predicted_hashingvectorizer == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77389803505\n"
     ]
    }
   ],
   "source": [
    "#三层pipeline\n",
    "countvectorizer_tfidf_multinomialnb_pipeline = Pipeline([('count_vectorizer_transformer',CountVectorizer()),\n",
    "                                                        ('tfidf_transformer',TfidfTransformer()),\n",
    "                                                        ('multinomialnb_clf',MultinomialNB())])\n",
    "countvectorizer_tfidf_multinomialnb_pipeline.fit(X_train,y_train)\n",
    "y_predicted_countvectorizer_tfidf = countvectorizer_tfidf_multinomialnb_pipeline.predict(X_test)\n",
    "print(np.mean(y_predicted_countvectorizer_tfidf == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.80      0.52      0.63       319\n",
      "           comp.graphics       0.81      0.65      0.72       389\n",
      " comp.os.ms-windows.misc       0.82      0.65      0.73       394\n",
      "comp.sys.ibm.pc.hardware       0.67      0.78      0.72       392\n",
      "   comp.sys.mac.hardware       0.86      0.77      0.81       385\n",
      "          comp.windows.x       0.89      0.75      0.82       395\n",
      "            misc.forsale       0.93      0.69      0.80       390\n",
      "               rec.autos       0.85      0.92      0.88       396\n",
      "         rec.motorcycles       0.94      0.93      0.93       398\n",
      "      rec.sport.baseball       0.92      0.90      0.91       397\n",
      "        rec.sport.hockey       0.89      0.97      0.93       399\n",
      "               sci.crypt       0.59      0.97      0.74       396\n",
      "         sci.electronics       0.84      0.60      0.70       393\n",
      "                 sci.med       0.92      0.74      0.82       396\n",
      "               sci.space       0.84      0.89      0.87       394\n",
      "  soc.religion.christian       0.44      0.98      0.61       398\n",
      "      talk.politics.guns       0.64      0.94      0.76       364\n",
      "   talk.politics.mideast       0.93      0.91      0.92       376\n",
      "      talk.politics.misc       0.96      0.42      0.58       310\n",
      "      talk.religion.misc       0.97      0.14      0.24       251\n",
      "\n",
      "             avg / total       0.82      0.77      0.77      7532\n",
      "\n",
      "[[166   0   0   1   0   1   0   0   1   1   1   3   0   6   3 123   4   8\n",
      "    0   1]\n",
      " [  1 252  15  12   9  18   1   2   1   5   2  41   4   0   6  15   4   1\n",
      "    0   0]\n",
      " [  0  14 258  45   3   9   0   2   1   3   2  25   1   0   6  23   2   0\n",
      "    0   0]\n",
      " [  0   5  11 305  17   1   3   6   1   0   2  19  13   0   5   3   1   0\n",
      "    0   0]\n",
      " [  0   3   8  23 298   0   3   8   1   3   1  16   8   0   2   8   3   0\n",
      "    0   0]\n",
      " [  1  21  17  13   2 298   1   0   1   1   0  23   0   1   4  10   2   0\n",
      "    0   0]\n",
      " [  0   1   3  31  12   1 271  19   4   4   6   5  12   6   3   9   3   0\n",
      "    0   0]\n",
      " [  0   1   0   3   0   0   4 364   3   2   2   4   1   1   3   3   4   0\n",
      "    1   0]\n",
      " [  0   0   0   1   0   0   2  10 371   0   0   4   0   0   0   8   2   0\n",
      "    0   0]\n",
      " [  0   0   0   0   1   0   0   4   0 357  22   0   0   0   2   9   1   1\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   1   0   4 387   1   0   0   1   5   0   0\n",
      "    0   0]\n",
      " [  0   2   1   0   0   1   1   3   0   0   0 383   1   0   0   3   1   0\n",
      "    0   0]\n",
      " [  0   4   2  17   5   0   2   8   7   1   2  78 235   3  11  15   2   1\n",
      "    0   0]\n",
      " [  2   3   0   1   1   3   1   0   2   3   4  11   5 292   6  52   6   4\n",
      "    0   0]\n",
      " [  0   2   0   1   0   3   0   2   1   0   1   6   1   2 351  19   4   0\n",
      "    1   0]\n",
      " [  2   0   0   0   0   0   0   0   1   0   0   0   0   1   2 392   0   0\n",
      "    0   0]\n",
      " [  0   0   0   1   0   0   2   0   1   1   0  10   0   0   1   6 341   1\n",
      "    0   0]\n",
      " [  0   1   0   0   0   0   0   0   0   1   0   2   0   0   0  24   3 344\n",
      "    1   0]\n",
      " [  2   0   0   0   0   0   0   1   0   0   1  11   0   1   7  35 118   5\n",
      "  129   0]\n",
      " [ 33   2   0   0   0   0   0   0   0   1   1   3   0   4   4 131  29   5\n",
      "    3  35]]\n"
     ]
    }
   ],
   "source": [
    "#结果报告\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test,y_predicted_countvectorizer_tfidf,target_names = news_dataset.target_names))\n",
    "print(metrics.confusion_matrix(y_test,y_predicted_countvectorizer_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#使用梯度搜索寻找最优参数\n",
    "#备选参数组成字典，键为pipeline中的转换器或分类器的名字加两个下划线加参数名，值为备选的参数值\n",
    "#GridSearchCV返回一个分类器，对训练数据拟合后产生最优参数best_params_\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'count_vectorizer_transformer__ngram_range':[(1, 1), (1, 2)],\n",
    "              'tfidf_transformer__use_idf':(True,False),\n",
    "              'multinomialnb_clf__alpha':(1,0.3,0.1,0.03,0.01,0.003,0.001),}\n",
    "gs_clf = GridSearchCV(countvectorizer_tfidf_multinomialnb_pipeline,parameters,n_jobs = -1)\n",
    "gs_clf.fit(X_train[:400],y_train[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "{'count_vectorizer_transformer__ngram_range': (1, 1), 'multinomialnb_clf__alpha': 0.003, 'tfidf_transformer__use_idf': True}\n",
      "('count_vectorizer_transformer__ngram_range', (1, 1))\n",
      "('multinomialnb_clf__alpha', 0.003)\n",
      "('tfidf_transformer__use_idf', True)\n"
     ]
    }
   ],
   "source": [
    "print(gs_clf.best_score_)\n",
    "print(gs_clf.best_params_)\n",
    "for item in gs_clf.best_params_.items():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#注：\n",
    "#一、CountVectorizer,TfidfVectorizer,HashingVectorizer都有stop_words参数，用于忽略一些不想列入计算的单词，比如\n",
    "#频繁出现的单词\n",
    "#二、HashingVectorizer有non_negative参数，需要设为True\n",
    "#三、MultinomialNB有alpha参数，用于指定拉普拉斯平滑系数，默认为1\n",
    "#四、词根还原（stemming）与词形还原（lemmatization）可以提高分类器准确率\n",
    "#五、关于特征提取的详细介绍http://blog.csdn.net/u013719780/article/details/51743867"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
