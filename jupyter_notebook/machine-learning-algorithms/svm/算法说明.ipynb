{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#概念：svm根据支持向量搜索最优分离超平面。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$数据线性可分的情况\\\\\n",
       "svm通过搜索最大边缘超平面找到最优分离超平面\\\\\n",
       "分离超平面H:W^TX+b = 0\\\\\n",
       "对于二维数据\\\\\n",
       "分离超平面H:b+w_1x_1+w_2x_2=0\\\\\n",
       "位于H上方的点满足:b+w_1x_1+w_2x_2>0\\\\\n",
       "位于H下方的点满足:b+w_1x_1+w_2x_2<0\\\\\n",
       "调整权重使得：\\\\\n",
       "\\begin{cases}上边缘超平面H1:\\ b+w_1x_1+w_2x_2=1\\\\\n",
       "下边缘超平面H2:\\ b+w_1x_1+w_2x_2=-1\\end{cases}\\\\\n",
       "H1或H1上方的元组都属于第一类，H2或H2下方的元组都属于第二类\\\\\n",
       "即：\\\\\n",
       "y=1时，b+w_1x_1+w_2x_2\\geq1\\\\\n",
       "y=-1时,b+w_1x_1+w_2x_2\\leq-1\\\\\n",
       "两式合并，对所有元组都有：\\\\\n",
       "y^i(b+w_1x_1^i+w_2x_2^i)\\geq1\\\\\n",
       "落在边缘超平面上的元组最难分类，给出了最多的分类信息，因此被称为支持向量。\\\\\n",
       "最大边缘即分离超平面到边缘超平面之间的最大距离：\\\\\n",
       "d = \\frac1{\\sqrt{W^TW}} = \\frac{1}{||W||}\\\\\n",
       "svm如何找出最优分离超平面和支持向量：\\\\\n",
       "面临的问题：\\\\\n",
       "max\\ \\frac{1}{||W||} \\ s.t.\\ y^i(b+w_1x_1^i+w_2x_2^i)\\geq1\n",
       "通过kkt条件法求解。\\\\\n",
       "(我的理解)得到决策边界:d(X) = W^T+b = (\\sum\\limits_{i = 1}^{m}\\alpha^iy^iX^i)^TX+b\\\\\n",
       "(我的理解)其中X是待分类元组，X^i代表所有向量，从1到m，y^i代表所有向量类标号，\\alpha^i和b由凸二次优化得到，分别是拉格朗日乘子和截距\\\\\n",
       "(我的理解)注意：决策边界中不涉及W,因为可以证明，W=\\sum\\limits_{i = 1}^{m}\\alpha^iy^iX^i\\\\\n",
       "(数据挖掘：概念与技术)得到决策边界:d(X) = \\sum\\limits_{i = 1}^{l}y^i\\alpha^i(X^i)^TX+b\\\\\n",
       "(数据挖掘：概念与技术)其中X是待分类元组，X^i代表支持向量，从1到l，y^i代表支持向量类标号，\\alpha^i和b由凸二次优化得到，分别是拉格朗日乘子和截距\\\\\n",
       "给定待分类元组，带入上式，检查结果符号:\\\\\n",
       "正代表在最优分离超平面上方，元组属于类1，负代表在最优分离超平面下方，元组属于类-1$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "$数据线性可分的情况\\\\\n",
    "svm通过搜索最大边缘超平面找到最优分离超平面\\\\\n",
    "分离超平面H:W^TX+b = 0\\\\\n",
    "对于二维数据\\\\\n",
    "分离超平面H:b+w_1x_1+w_2x_2=0\\\\\n",
    "位于H上方的点满足:b+w_1x_1+w_2x_2>0\\\\\n",
    "位于H下方的点满足:b+w_1x_1+w_2x_2<0\\\\\n",
    "调整权重使得：\\\\\n",
    "\\begin{cases}上边缘超平面H1:\\ b+w_1x_1+w_2x_2=1\\\\\n",
    "下边缘超平面H2:\\ b+w_1x_1+w_2x_2=-1\\end{cases}\\\\\n",
    "H1或H1上方的元组都属于第一类，H2或H2下方的元组都属于第二类\\\\\n",
    "即：\\\\\n",
    "y=1时，b+w_1x_1+w_2x_2\\geq1\\\\\n",
    "y=-1时,b+w_1x_1+w_2x_2\\leq-1\\\\\n",
    "两式合并，对所有元组都有：\\\\\n",
    "y^i(b+w_1x_1^i+w_2x_2^i)\\geq1\\\\\n",
    "落在边缘超平面上的元组最难分类，给出了最多的分类信息，因此被称为支持向量。\\\\\n",
    "最大边缘即分离超平面到边缘超平面之间的最大距离：\\\\\n",
    "d = \\frac1{\\sqrt{W^TW}} = \\frac{1}{||W||}\\\\\n",
    "svm如何找出最优分离超平面和支持向量：\\\\\n",
    "面临的问题：\\\\\n",
    "max\\ \\frac{1}{||W||} \\ s.t.\\ y^i(b+w_1x_1^i+w_2x_2^i)\\geq1\n",
    "通过kkt条件法求解。\\\\\n",
    "(我的理解)得到决策边界:d(X) = W^T+b = (\\sum\\limits_{i = 1}^{m}\\alpha^iy^iX^i)^TX+b\\\\\n",
    "(我的理解)其中X是待分类元组，X^i代表所有向量，从1到m，y^i代表所有向量类标号，\\alpha^i和b由凸二次优化得到，分别是拉格朗日乘子和截距\\\\\n",
    "(我的理解)注意：决策边界中不涉及W,因为可以证明，W=\\sum\\limits_{i = 1}^{m}\\alpha^iy^iX^i\\\\\n",
    "(数据挖掘：概念与技术)得到决策边界:d(X) = \\sum\\limits_{i = 1}^{l}y^i\\alpha^i(X^i)^TX+b\\\\\n",
    "(数据挖掘：概念与技术)其中X是待分类元组，X^i代表支持向量，从1到l，y^i代表支持向量类标号，\\alpha^i和b由凸二次优化得到，分别是拉格朗日乘子和截距\\\\\n",
    "给定待分类元组，带入上式，检查结果符号:\\\\\n",
    "正代表在最优分离超平面上方，元组属于类1，负代表在最优分离超平面下方，元组属于类-1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#svm复杂度由支持向量数而不是数据维度决定，因此不容易过拟合\n",
    "#svm由支持向量决定，删除其他元组将会得到相同的分离超平面，因此具有少量支持向量的svm具有很好的泛化能力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$数据非线性可分的情况\\\\\n",
       "非线性svm\\\\\n",
       "第一步：用非线性映射将原数据映射到高维空间中去\\\\\n",
       "第二步：在新的空间中搜索最优分离超平面，即数据线性可分的情况\\\\\n",
       "例如：\\\\\n",
       "将3维元组X(x_1,x_2,x_3)映射到6维空间Z中去\\\\\n",
       "\\phi_1(X) = x_1,\\phi_2(X) = x_2,\\phi_3(X) = x_3,\\phi_4(X) = x_1^2,\\phi_5(X) = x_1x_2,\\phi_6(X) = x_1x_3\\\\\n",
       "新空间中，决策超平面是d(Z) = W^TZ+b\\\\\n",
       "替换到3维空间中去，d(X) = W^TX+b = w_1x_1+w_2x_2+w_3x_3+w_4x_1^2+w_5x_1x_2+w_6x_1x_3+b\\\\\n",
       "存在的问题：\\\\\n",
       "一、如何选择非线性映射\n",
       "二、计算开销大\\\\\n",
       "解决方法：\\\\\n",
       "在新空间中对凸二次优化求解时，仅涉及对Z^i·Z^j = \\phi(X^i)·\\phi(X^j)点积的计算\\\\\n",
       "这等价于将核函数K(X^i,X^j)应用于原空间中的数据，即:\\\\\n",
       "Z^i·Z^j = \\phi(X^i)·\\phi(X^j) = K(X^i,X^j)\\\\\n",
       "在原低维空间进行计算，避免了映射(事实上，我们根本不需要知道映射是什么)，大大降低了计算开销。 $"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "$数据非线性可分的情况\\\\\n",
    "非线性svm\\\\\n",
    "第一步：用非线性映射将原数据映射到高维空间中去\\\\\n",
    "第二步：在新的空间中搜索最优分离超平面，即数据线性可分的情况\\\\\n",
    "例如：\\\\\n",
    "将3维元组X(x_1,x_2,x_3)映射到6维空间Z中去\\\\\n",
    "\\phi_1(X) = x_1,\\phi_2(X) = x_2,\\phi_3(X) = x_3,\\phi_4(X) = x_1^2,\\phi_5(X) = x_1x_2,\\phi_6(X) = x_1x_3\\\\\n",
    "新空间中，决策超平面是d(Z) = W^TZ+b\\\\\n",
    "替换到3维空间中去，d(X) = W^TX+b = w_1x_1+w_2x_2+w_3x_3+w_4x_1^2+w_5x_1x_2+w_6x_1x_3+b\\\\\n",
    "存在的问题：\\\\\n",
    "一、如何选择非线性映射\n",
    "二、计算开销大\\\\\n",
    "解决方法：\\\\\n",
    "在新空间中对凸二次优化求解时，仅涉及对Z^i·Z^j = \\phi(X^i)·\\phi(X^j)点积的计算\\\\\n",
    "这等价于将核函数K(X^i,X^j)应用于原空间中的数据，即:\\\\\n",
    "Z^i·Z^j = \\phi(X^i)·\\phi(X^j) = K(X^i,X^j)\\\\\n",
    "在原低维空间进行计算，避免了映射(事实上，我们根本不需要知道映射是什么)，大大降低了计算开销。 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$核函数种类\\\\\n",
       "一、h次多项式核函数：K(X_i,X_j) = (X_i·X_j+1)^h\\\\\n",
       "二、高斯径向基函数核函数：K(X_i,X_j) = e^{-\\frac{||X_i-X_j||^2}{2\\sigma^2}}\\\\\n",
       "三、S型核函数：K(X_i,X_j) = tanh(kX_i·X_j-\\delta) $"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "$核函数种类\\\\\n",
    "一、h次多项式核函数：K(X_i,X_j) = (X_i·X_j+1)^h\\\\\n",
    "二、高斯径向基函数核函数：K(X_i,X_j) = e^{-\\frac{||X_i-X_j||^2}{2\\sigma^2}}\\\\\n",
    "三、S型核函数：K(X_i,X_j) = tanh(kX_i·X_j-\\delta) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$对于如何寻找最大边缘超平面，面临的问题是：\\\\\n",
       "max\\ \\frac1{||W||}\\ \\ s.t.\\ y^i(W^TX^i+b)\\geq1\\\\\n",
       "转化为等价的:\\\\\n",
       "min\\ ||W||^2\\ \\ s.t.\\ y^i(W^TX^i+b)\\geq1\\\\\n",
       "目标函数是二次的，约束条件是线性的，所以它是一个凸二次优化问题\\\\\n",
       "可以直接求解，但为了更高效求解，通过KKT条件法求最优解\\\\\n",
       "优点在于：一者对偶问题往往更容易求解；二者可以自然的引入核函数，进而推广到非线性分类问题\\\\\n",
       "通过KKT条件法，问题转换为等价的：\\\\\n",
       "L(W,b,\\alpha) = ||W||^2-\\sum\\limits_{i=1}^{m}\\alpha^i(y^i(W^TX^i+b)-1)\\ \\ s.t.\\ \\alpha^i\\geq0\\\\\n",
       "通过KKT条件，找到满足所有约束条件的最优解。$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "$对于如何寻找最大边缘超平面，面临的问题是：\\\\\n",
    "max\\ \\frac1{||W||}\\ \\ s.t.\\ y^i(W^TX^i+b)\\geq1\\\\\n",
    "转化为等价的:\\\\\n",
    "min\\ ||W||^2\\ \\ s.t.\\ y^i(W^TX^i+b)\\geq1\\\\\n",
    "目标函数是二次的，约束条件是线性的，所以它是一个凸二次优化问题\\\\\n",
    "可以直接求解，但为了更高效求解，通过KKT条件法求最优解\\\\\n",
    "优点在于：一者对偶问题往往更容易求解；二者可以自然的引入核函数，进而推广到非线性分类问题\\\\\n",
    "通过KKT条件法，问题转换为等价的：\\\\\n",
    "L(W,b,\\alpha) = ||W||^2-\\sum\\limits_{i=1}^{m}\\alpha^i(y^i(W^TX^i+b)-1)\\ \\ s.t.\\ \\alpha^i\\geq0\\\\\n",
    "通过KKT条件，找到满足所有约束条件的最优解。$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$优化(最值)问题有三种：\\\\\n",
       "一、无约束条件\\\\\n",
       "f(X)\\\\\n",
       "求解方法：直接求偏导，令偏导等于0。\\\\\n",
       "\\frac{\\partial f(X)}{\\partial X} = 0\\\\\n",
       "二、等式约束\\\\\n",
       "f(X)\\ s.t.\\  g^i(X) = a^i\\\\\n",
       "求解方法：拉格朗日乘子法，将约束条件乘上拉格朗日乘子添加到目标函数中。对目标变量X和拉格朗日乘子\\alpha分别求偏导，令偏导等于0。\\\\\n",
       "L(X) = f(X)+\\sum\\limits_{i=1}^k\\alpha^i(g^i(X)-a^i)\\ s.t.\\ \\alpha^i\\neq0\\\\\n",
       "\\frac{\\partial L(X)}{\\partial X}=0,\\frac{\\partial L(X)}{\\partial \\alpha^i}=0\\\\\n",
       "三、不等式约束\\\\\n",
       "f(X)\\ s.t.\\ g^i(X)\\leq a^i或\\ g^i(X)\\geq a^i\\\\\n",
       "求解方法：KKT条件法。将不等式约束条件乘上拉格朗日乘子添加到目标函数中。\\\\\n",
       "L(X) = f(X)+\\sum\\limits_{i=1}^k\\alpha^i(g^i(X)-a^i)\\ s.t.\\alpha^i\\geq0\\\\\n",
       "KKT条件：即L(X)取极值的必要条件。\\\\\n",
       "1.\\ \\frac{\\partial L(X)}{\\partial X}=0\\\\\n",
       "2.\\ \\alpha^ig^i(X)=0,\\alpha^i\\geq0\\\\\n",
       "通过KKT条件得到W，\\alpha的所有可能解(所以KKT条件是去极值的必要而非充分条件)，找出满足所有约束条件的解即为最优解。$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "$优化(最值)问题有三种：\\\\\n",
    "一、无约束条件\\\\\n",
    "f(X)\\\\\n",
    "求解方法：直接求偏导，令偏导等于0。\\\\\n",
    "\\frac{\\partial f(X)}{\\partial X} = 0\\\\\n",
    "二、等式约束\\\\\n",
    "f(X)\\ s.t.\\  g^i(X) = a^i\\\\\n",
    "求解方法：拉格朗日乘子法，将约束条件乘上拉格朗日乘子添加到目标函数中。对目标变量X和拉格朗日乘子\\alpha分别求偏导，令偏导等于0。\\\\\n",
    "L(X) = f(X)+\\sum\\limits_{i=1}^k\\alpha^i(g^i(X)-a^i)\\ s.t.\\ \\alpha^i\\neq0\\\\\n",
    "\\frac{\\partial L(X)}{\\partial X}=0,\\frac{\\partial L(X)}{\\partial \\alpha^i}=0\\\\\n",
    "三、不等式约束\\\\\n",
    "f(X)\\ s.t.\\ g^i(X)\\leq a^i或\\ g^i(X)\\geq a^i\\\\\n",
    "求解方法：KKT条件法。将不等式约束条件乘上拉格朗日乘子添加到目标函数中。\\\\\n",
    "L(X) = f(X)+\\sum\\limits_{i=1}^k\\alpha^i(g^i(X)-a^i)\\ s.t.\\alpha^i\\geq0\\\\\n",
    "KKT条件：即L(X)取极值的必要条件。\\\\\n",
    "1.\\ \\frac{\\partial L(X)}{\\partial X}=0\\\\\n",
    "2.\\ \\alpha^ig^i(X)=0,\\alpha^i\\geq0\\\\\n",
    "通过KKT条件得到W，\\alpha的所有可能解(所以KKT条件是取极值的必要而非充分条件)，找出满足所有约束条件的解即为最优解。$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$思路\\\\\n",
       "一、设分离超平面H:W^TX+b=0\\\\\n",
       "空间中有很多这样的分离超平面，要找一个最优的\\\\\n",
       "二、增加约束条件，缩小分离超平面范围\\\\\n",
       "s.t.\\ 当y=1时，W^TX+b>0时;当y=-1时，W^TX+b<0\\\\\n",
       "保证了超平面两侧数据属于不同类。\\\\\n",
       "三、增加约束条件，获取边缘超平面(此处并未缩小分离超平面范围)\\\\\n",
       "s.t.\\ 当y=1，W^TX+b\\geq1时;当y=-1，W^TX+b\\leq-1时\\\\\n",
       "注意：此处选择1和-1主要是为了便于后面的计算，选择的数值对寻找最优分离超平面没有影响，因为后面求W和b的最优解时，\n",
       "会自动调整W和b的大小，以满足约束条件。\\\\\n",
       "边缘超平面H1:W^TX+b=1;H2:W^TX+b=-1\\\\\n",
       "四、寻找最优分离超平面\\\\\n",
       "计算边缘超平面到分离超平面的距离使其最大化，得到W和b，W^TX+b=0即最优分离超平面，h(X)=W^TX+b即决策函数。 $"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "$思路\\\\\n",
    "一、设分离超平面H:W^TX+b=0\\\\\n",
    "空间中有很多这样的分离超平面，要找一个最优的\\\\\n",
    "二、增加约束条件，缩小分离超平面范围\\\\\n",
    "s.t.\\ 当y=1时，W^TX+b>0时;当y=-1时，W^TX+b<0\\\\\n",
    "保证了超平面两侧数据属于不同类。\\\\\n",
    "三、增加约束条件，获取边缘超平面(此处并未缩小分离超平面范围)\\\\\n",
    "s.t.\\ 当y=1，W^TX+b\\geq1时;当y=-1，W^TX+b\\leq-1时\\\\\n",
    "注意：此处选择1和-1主要是为了便于后面的计算，选择的数值对寻找最优分离超平面没有影响，因为后面求W和b的最优解时，\n",
    "会自动调整W和b的大小，以满足约束条件。\\\\\n",
    "边缘超平面H1:W^TX+b=1;H2:W^TX+b=-1\\\\\n",
    "四、寻找最优分离超平面\\\\\n",
    "计算边缘超平面到分离超平面的距离使其最大化，得到W和b，W^TX+b=0即最优分离超平面，h(X)=W^TX+b即决策函数。 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$SMO算法\\\\\n",
       "在用KTT条件法求解凸二次优化问题时，人们以前用二次规划(quadratic solver)求解：\\\\\n",
       "KTT条件要求:\\\\\n",
       "1.\\ \\frac{\\partial L(X)}{\\partial X}=0\\\\\n",
       "2.\\ \\alpha^ig^i(X)=0,\\alpha^i\\geq0\\\\\n",
       "计算消耗非常大\\\\\n",
       "John\\ Platt发明了SMO(Sequential Minimal Optimazation)算法(序列最小化):\\\\\n",
       "由\\alpha^ig^i(X)=0得到\\sum\\limits_{i = 1}^{m}\\alpha^ig^i(X)=0\\\\\n",
       "SMO工作原理：每次循环选择两个\\alpha进行优化处理，一旦找到一对合适的\\alpha就增大一个同时减小另一个。\\\\\n",
       "所谓合适即：\\alpha必须在边缘超平面之外而非之上$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "$SMO算法\\\\\n",
    "在用KTT条件法求解凸二次优化问题时，人们以前用二次规划(quadratic solver)求解：\\\\\n",
    "KTT条件要求:\\\\\n",
    "1.\\ \\frac{\\partial L(X)}{\\partial X}=0\\\\\n",
    "2.\\ \\alpha^ig^i(X)=0,\\alpha^i\\geq0\\\\\n",
    "计算消耗非常大\\\\\n",
    "John\\ Platt发明了SMO(Sequential Minimal Optimazation)算法(序列最小化):\\\\\n",
    "由\\alpha^ig^i(X)=0得到\\sum\\limits_{i = 1}^{m}\\alpha^ig^i(X)=0\\\\\n",
    "SMO工作原理：每次循环选择两个\\alpha进行优化处理，一旦找到一对合适的\\alpha就增大一个同时减小另一个。\\\\\n",
    "所谓合适即：\\alpha必须在边缘超平面之外而非之上$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
